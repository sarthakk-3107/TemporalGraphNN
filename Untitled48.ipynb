{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn\n",
        "from torch_geometric.nn.models.tgn import TGNMemory, IdentityMessage, LastAggregator"
      ],
      "metadata": {
        "id": "KN3HPw8w00Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -q torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "\n",
        "import torch\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda, \"| GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnbKP4ecyaKN",
        "outputId": "6125e757-d6ef-48ef-ea7e-7ee83519293a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126 | CUDA: 12.6 | GPU: CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PATCH 1: Build TemporalData with label propagation + int64 timestamps ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import TemporalData\n",
        "\n",
        "def load_temporal_from_csvs_LABELPROP(data_dir: str = \".\"):\n",
        "    feats = pd.read_csv(\"/content/features.csv\")\n",
        "    labs  = pd.read_csv(f\"/content/labels.csv\")\n",
        "    ed    = pd.read_csv(f\"/content/edges.csv\")\n",
        "\n",
        "    # Map node_id -> 0..N-1\n",
        "    node_ids = np.sort(feats[\"node_id\"].unique())\n",
        "    nid_map = {nid: i for i, nid in enumerate(node_ids)}\n",
        "    num_nodes = len(node_ids)\n",
        "\n",
        "    feats[\"nid\"]   = feats[\"node_id\"].map(nid_map)\n",
        "    ed[\"src_nid\"]  = ed[\"src\"].map(nid_map)\n",
        "    ed[\"dst_nid\"]  = ed[\"dst\"].map(nid_map)\n",
        "    labs[\"nid\"]    = labs[\"node_id\"].map(nid_map)\n",
        "\n",
        "    # --- Edges (timestamps as int64/Long) ---\n",
        "    src = torch.tensor(ed[\"src_nid\"].to_numpy(), dtype=torch.long)\n",
        "    dst = torch.tensor(ed[\"dst_nid\"].to_numpy(), dtype=torch.long)\n",
        "    t_e = torch.tensor(ed[\"timestamp\"].to_numpy(), dtype=torch.long)\n",
        "\n",
        "    # Node features per (node, time)\n",
        "    ignore = {\"node_id\",\"nid\",\"timestamp\"}\n",
        "    feat_cols = [c for c in feats.columns if c not in ignore and np.issubdtype(feats[c].dtype, np.number)]\n",
        "\n",
        "    x_list, n_list, t_list = [], [], []\n",
        "    for t_val, frame in feats.groupby(\"timestamp\"):\n",
        "        frame = frame.sort_values(\"nid\")\n",
        "        x_list.append(torch.tensor(frame[feat_cols].to_numpy(np.float32), dtype=torch.float))\n",
        "        n_list.append(torch.tensor(frame[\"nid\"].to_numpy(np.int64), dtype=torch.long))\n",
        "        t_list.append(torch.full((len(frame),), int(t_val), dtype=torch.long))  # int64 node times\n",
        "\n",
        "    x    = torch.cat(x_list, dim=0)\n",
        "    n_id = torch.cat(n_list, dim=0)\n",
        "    t_n  = torch.cat(t_list, dim=0)\n",
        "\n",
        "    data = TemporalData(src=src, dst=dst, t=t_e, x=x, n_id=n_id, t_n=t_n)\n",
        "\n",
        "    # -------- Label propagation: use each node's final label for ALL its timestamps --------\n",
        "    labs_sorted = labs.sort_values([\"nid\", \"timestamp\"])\n",
        "    labs_last = labs_sorted.groupby(\"nid\").tail(1)  # final label per node\n",
        "    node_label = {int(r.nid): int(r.label) for r in labs_last.itertuples(index=False)}\n",
        "\n",
        "    # Assign label to every (nid, t) occurrence\n",
        "    y_n = torch.tensor([node_label.get(int(i), -1) for i in n_id.tolist()], dtype=torch.long)\n",
        "    data.y_n = y_n\n",
        "\n",
        "    in_channels = x.size(1)\n",
        "    return data, num_nodes, in_channels\n"
      ],
      "metadata": {
        "id": "fE3UCA6wALe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PATCH 2: Reload using label propagation, split by EDGE times, and train (with memory.detach) ---\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.loader import TemporalDataLoader\n",
        "\n",
        "# Assumes:\n",
        "# - load_temporal_from_csvs_LABELPROP(.) from Patch 1 is defined\n",
        "# - TGNClassifier (version-robust) is defined\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 1) Reload data (labels exist at ALL timestamps thanks to Patch 1)\n",
        "data, num_nodes, in_ch = load_temporal_from_csvs_LABELPROP(\".\")\n",
        "loader = TemporalDataLoader(data, batch_size=4096, shuffle=True)\n",
        "\n",
        "# 2) Build edge-time splits with guarantees for small T\n",
        "edge_times = torch.unique(data.t).cpu().tolist()\n",
        "edge_times = sorted(int(t) for t in edge_times)\n",
        "n = len(edge_times)\n",
        "\n",
        "if n == 1:\n",
        "    times_train = [edge_times[0]]\n",
        "    times_val   = [edge_times[0]]\n",
        "    times_test  = [edge_times[0]]\n",
        "elif n == 2:\n",
        "    times_train = [edge_times[0]]\n",
        "    times_val   = [edge_times[1]]\n",
        "    times_test  = [edge_times[1]]\n",
        "elif n == 3:\n",
        "    times_train = [edge_times[0]]\n",
        "    times_val   = [edge_times[1]]\n",
        "    times_test  = [edge_times[2]]\n",
        "else:\n",
        "    n_train = max(1, int(round(0.6 * n)))\n",
        "    n_val   = max(1, int(round(0.2 * n)))\n",
        "    if n_train + n_val >= n:\n",
        "        n_val = max(1, n - n_train - 1)\n",
        "    n_test = n - n_train - n_val\n",
        "    if n_test < 1:\n",
        "        steal = 1 - n_test\n",
        "        n_train = max(1, n_train - steal)\n",
        "        n_test = 1\n",
        "    times_train = edge_times[:n_train]\n",
        "    times_val   = edge_times[n_train:n_train+n_val]\n",
        "    times_test  = edge_times[n_train+n_val:]\n",
        "\n",
        "times_train_set = set(times_train)\n",
        "times_val_set   = set(times_val)\n",
        "times_test_set  = set(times_test)\n",
        "\n",
        "def _mask_for_phase(batch_t: torch.Tensor, phase: str) -> torch.Tensor:\n",
        "    \"\"\"Return a boolean mask selecting events in this batch_t that belong to the given phase.\"\"\"\n",
        "    if phase == \"train\":\n",
        "        pool = times_train_set\n",
        "    elif phase == \"val\":\n",
        "        pool = times_val_set\n",
        "    else:\n",
        "        pool = times_test_set\n",
        "    pool_t = torch.tensor(list(pool), dtype=batch_t.dtype, device=batch_t.device)\n",
        "    # Prefer torch.isin, fallback to OR of equalities\n",
        "    try:\n",
        "        return torch.isin(batch_t, pool_t)\n",
        "    except AttributeError:\n",
        "        if pool_t.numel() == 0:\n",
        "            return torch.zeros_like(batch_t, dtype=torch.bool)\n",
        "        m = (batch_t == pool_t[0])\n",
        "        for k in range(1, pool_t.numel()):\n",
        "            m = m | (batch_t == pool_t[k])\n",
        "        return m\n",
        "\n",
        "# 3) Model / optimizer / loss\n",
        "model = TGNClassifier(num_nodes=num_nodes, in_channels=in_ch).to(device)\n",
        "opt   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "crit  = nn.CrossEntropyLoss()\n",
        "\n",
        "def run_epoch(train: bool = True, phase: str = \"train\"):\n",
        "    \"\"\"\n",
        "    phase âˆˆ {\"train\",\"val\",\"test\"}.\n",
        "    Uses per-event masks from edge TIMES to pick which events contribute to loss/metrics.\n",
        "    Detaches TGN memory after each batch to avoid backprop-through-history errors.\n",
        "    \"\"\"\n",
        "    (model.train() if train else model.eval())\n",
        "    model.reset_memory()\n",
        "\n",
        "    tot_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        event_mask = _mask_for_phase(batch.t, phase)\n",
        "        if not bool(event_mask.any()):\n",
        "            try: model.memory.detach()\n",
        "            except AttributeError: model.reset_memory()\n",
        "            continue\n",
        "\n",
        "        # Messages: zeros (alignment-safe). Replace with per-event features if desired:\n",
        "        # msg = data.x[batch.src].to(device)\n",
        "        msg = torch.zeros((batch.src.size(0), in_ch), dtype=torch.float, device=device)\n",
        "\n",
        "        logits = model(batch.src, batch.dst, batch.t, msg)\n",
        "\n",
        "        # Labels have been propagated to all timestamps; just apply event mask\n",
        "        y_full = data.y_n[batch.dst].to(device)\n",
        "        y_sel  = torch.where(event_mask, y_full, torch.full_like(y_full, -1))\n",
        "        sel    = (y_sel >= 0)\n",
        "        if not bool(sel.any()):\n",
        "            try: model.memory.detach()\n",
        "            except AttributeError: model.reset_memory()\n",
        "            continue\n",
        "\n",
        "        if train and phase == \"train\":\n",
        "            opt.zero_grad()\n",
        "            loss = crit(logits[sel], y_sel[sel])\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            tot_loss += float(loss.item())\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                loss = crit(logits[sel], y_sel[sel])\n",
        "                tot_loss += float(loss.item())\n",
        "\n",
        "        # ðŸ”‘ Critical for TGN: cut the graph between batches\n",
        "        try: model.memory.detach()\n",
        "        except AttributeError: model.reset_memory()\n",
        "\n",
        "        pred = logits.argmax(dim=-1)\n",
        "        correct += int((pred[sel] == y_sel[sel]).sum().item())\n",
        "        total   += int(sel.sum().item())\n",
        "\n",
        "    acc = (correct / total) if total else 0.0\n",
        "    return tot_loss, acc\n",
        "\n",
        "# 4) Train / validate / test\n",
        "for ep in range(1, 11):\n",
        "    tr_loss, tr_acc = run_epoch(train=True,  phase=\"train\")\n",
        "    _,      val_acc = run_epoch(train=False, phase=\"val\")\n",
        "    print(f\"Epoch {ep:02d} | train_loss={tr_loss:.3f} | train_acc={tr_acc:.3f} | val_acc={val_acc:.3f}\")\n",
        "\n",
        "_, test_acc = run_epoch(train=False, phase=\"test\")\n",
        "print(\"Test acc =\", round(test_acc, 3))\n",
        "print(\"Times used -> train:\", times_train, \"| val:\", times_val, \"| test:\", times_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyYLZOKbV76f",
        "outputId": "a4c04a53-495a-44de-b4c9-9f073450ec07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train_loss=5.259 | train_acc=0.859 | val_acc=0.857\n",
            "Epoch 02 | train_loss=4.281 | train_acc=0.859 | val_acc=0.857\n",
            "Epoch 03 | train_loss=4.234 | train_acc=0.859 | val_acc=0.857\n",
            "Epoch 04 | train_loss=4.205 | train_acc=0.859 | val_acc=0.857\n",
            "Epoch 05 | train_loss=4.152 | train_acc=0.859 | val_acc=0.857\n",
            "Epoch 06 | train_loss=4.166 | train_acc=0.859 | val_acc=0.857\n",
            "Epoch 07 | train_loss=4.140 | train_acc=0.859 | val_acc=0.857\n",
            "Epoch 08 | train_loss=4.151 | train_acc=0.859 | val_acc=0.857\n",
            "Epoch 09 | train_loss=4.123 | train_acc=0.859 | val_acc=0.857\n"
          ]
        }
      ]
    }
  ]
}